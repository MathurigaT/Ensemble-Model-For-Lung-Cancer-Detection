{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUIdL9nEI3RK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "root_dir = \"drive/MyDrive/NewLungData\""
      ],
      "metadata": {
        "id": "EEhBubJLJPyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define data directory\n",
        "data_dir = \"drive/MyDrive/NewLungData\"\n",
        "\n",
        "# Define mean and standard deviation for normalization\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "# Define image size\n",
        "image_size = (256, 256)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Define data generators for train, validation, and test sets\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'train'),\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'val'),\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'test'),\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "OG8T9wWgJVtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained VGG16 model\n",
        "base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n"
      ],
      "metadata": {
        "id": "wgotC4CkJWwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze convolutional base to prevent weights are being updated during training process\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "CcgI0WzfJkJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base model architecture\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "NR-fBsR0JpqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add custom classification layers\n",
        "dropout_rate = 0.5\n",
        "num_classes = 2\n",
        "\n",
        "# Define the fully connected layers\n",
        "classifier = tf.keras.Sequential([\n",
        "    # Use GlobalAveragePooling2D instead of Flatten\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Concatenate the pre-trained convolutional base with the new classifier\n",
        "model = tf.keras.Sequential([base_model, classifier])\n"
      ],
      "metadata": {
        "id": "5ckNNptsKYiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate,weight_decay=1e-5),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_mLN4QuVZ6PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Ez2c9kMmaQGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_epochs = 10\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=initial_epochs, validation_data=val_generator,callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "U7q-t1lBaTdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print('Test accuracy: ', str(accuracy))\n",
        "\n",
        "# Define the file path where you want to save the model\n",
        "model_save_path =  \"drive/MyDrive/NewLungData/tenserflowModels/vgg16\""
      ],
      "metadata": {
        "id": "H22oCSz624HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No of layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))"
      ],
      "metadata": {
        "id": "JTnrsbq93gdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define grid search parameters for fine-tuning layers\n",
        "fine_tune_layers= [15,10,5]"
      ],
      "metadata": {
        "id": "7NIJsmpe2_-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# Perform grid search for fine-tuning layers\n",
        "results = []\n",
        "for fine_tune_at in fine_tune_layers:\n",
        "    print(\"-----------------------------------------------------\")\n",
        "    print(\"Freeze the layers before layer:\", fine_tune_at)\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Freeze all the layers before the `fine_tune_at` layer\n",
        "    for layer in base_model.layers[:fine_tune_at]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "\n",
        "    print(\"Trainable parameters:\",trainable_params)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate/10,weight_decay=1e-5),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    fine_tune_epochs = 10\n",
        "    total_epochs =  initial_epochs + fine_tune_epochs\n",
        "\n",
        "    # Define early stopping criteria\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    history_fine = model.fit(train_generator, epochs=total_epochs, initial_epoch=history.epoch[-1],validation_data=val_generator,callbacks=[early_stopping])\n",
        "\n",
        "    loss, accuracy = model.evaluate(test_generator)\n",
        "    print('Test accuracy of',fine_tune_at,\"is : \", str(accuracy))\n",
        "\n",
        "    # Define the file path where you want to save the model\n",
        "    model_save_path =  \"drive/MyDrive/NewLungData/tenserflowModels/vgg16_fn_\"+str(no_of_fine_tune_layer)\n",
        "\n",
        "    # Save the entire model to a single HDF5 file\n",
        "    model.save(model_save_path)"
      ],
      "metadata": {
        "id": "be-guNr23jdC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}